{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Site_of_source: https://www.ncdc.noaa.gov/stormevents/ftp.jsp\n",
    "# source: ftp://ftp.ncdc.noaa.gov/pub/data/swdi/stormevents/csvfiles/\n",
    "# Data_doc: ftp://ftp.ncdc.noaa.gov/pub/data/swdi/stormevents/csvfiles/Storm-Data-Bulk-csv-Format.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../data/storm_events_data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = ['StormEvents_d2000/StormEvents_details-ftp_v1.0_d2000_c20200707.csv',\n",
    "        'StormEvents_d2001/StormEvents_details-ftp_v1.0_d2001_c20200518.csv',\n",
    "        'StormEvents_d2002/StormEvents_details-ftp_v1.0_d2002_c20200518.csv',\n",
    "        'StormEvents_d2003/StormEvents_details-ftp_v1.0_d2003_c20200518.csv',\n",
    "        'StormEvents_d2004/StormEvents_details-ftp_v1.0_d2004_c20200518.csv',\n",
    "        'StormEvents_d2005/StormEvents_details-ftp_v1.0_d2005_c20200518.csv',\n",
    "        'StormEvents_d2006/StormEvents_details-ftp_v1.0_d2006_c20200518.csv',\n",
    "        'StormEvents_d2007/StormEvents_details-ftp_v1.0_d2007_c20170717.csv',\n",
    "        'StormEvents_d2008/StormEvents_details-ftp_v1.0_d2008_c20180718.csv',\n",
    "        'StormEvents_d2009/StormEvents_details-ftp_v1.0_d2009_c20180718.csv',\n",
    "        'StormEvents_d2010/StormEvents_details-ftp_v1.0_d2010_c20200716.csv',\n",
    "        'StormEvents_d2011/StormEvents_details-ftp_v1.0_d2011_c20180718.csv',\n",
    "        'StormEvents_d2012/StormEvents_details-ftp_v1.0_d2012_c20200317.csv',\n",
    "        'StormEvents_d2013/StormEvents_details-ftp_v1.0_d2013_c20170519.csv', \n",
    "        'StormEvents_d2014/StormEvents_details-ftp_v1.0_d2014_c20191116.csv',\n",
    "        'StormEvents_d2015/StormEvents_details-ftp_v1.0_d2015_c20191116.csv',\n",
    "        'StormEvents_d2016/StormEvents_details-ftp_v1.0_d2016_c20190817.csv', \n",
    "        'StormEvents_d2017/StormEvents_details-ftp_v1.0_d2017_c20200616.csv',\n",
    "        'StormEvents_d2018/StormEvents_details-ftp_v1.0_d2018_c20200716.csv',\n",
    "        'StormEvents_d2019/StormEvents_details-ftp_v1.0_d2019_c20200716.csv',\n",
    "        'StormEvents_d2020/StormEvents_details-ftp_v1.0_d2020_c20200716.csv'       \n",
    "       ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "for file in files:\n",
    "    data = pd.read_csv(path+file, low_memory=False)\n",
    "    df = df.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns='index', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['BEGIN_YEARMONTH', 'BEGIN_DAY', 'BEGIN_TIME', 'END_YEARMONTH',\n",
       "       'END_DAY', 'END_TIME', 'EPISODE_ID', 'EVENT_ID', 'STATE', 'STATE_FIPS',\n",
       "       'YEAR', 'MONTH_NAME', 'EVENT_TYPE', 'CZ_TYPE', 'CZ_FIPS', 'CZ_NAME',\n",
       "       'WFO', 'BEGIN_DATE_TIME', 'CZ_TIMEZONE', 'END_DATE_TIME',\n",
       "       'INJURIES_DIRECT', 'INJURIES_INDIRECT', 'DEATHS_DIRECT',\n",
       "       'DEATHS_INDIRECT', 'DAMAGE_PROPERTY', 'DAMAGE_CROPS', 'SOURCE',\n",
       "       'MAGNITUDE', 'MAGNITUDE_TYPE', 'FLOOD_CAUSE', 'CATEGORY', 'TOR_F_SCALE',\n",
       "       'TOR_LENGTH', 'TOR_WIDTH', 'TOR_OTHER_WFO', 'TOR_OTHER_CZ_STATE',\n",
       "       'TOR_OTHER_CZ_FIPS', 'TOR_OTHER_CZ_NAME', 'BEGIN_RANGE',\n",
       "       'BEGIN_AZIMUTH', 'BEGIN_LOCATION', 'END_RANGE', 'END_AZIMUTH',\n",
       "       'END_LOCATION', 'BEGIN_LAT', 'BEGIN_LON', 'END_LAT', 'END_LON',\n",
       "       'EPISODE_NARRATIVE', 'EVENT_NARRATIVE', 'DATA_SOURCE'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note:\n",
    "\n",
    "The Event type data has some inconsistent data enteries. For example, Hurricanes is set both as huricanes and hurricanes (Typhoon). We will set it to one entery value as huricane. Also, We are only interested in a few events: Hurriacnes, Drought, Wildfire, and Tornado.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Changing huricane (typhoons) to hurricane\n",
    "df['EVENT_TYPE'] = df['EVENT_TYPE'].map(lambda x: 'Hurricane' if x == 'Hurricane (Typhoon)' else x )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lowering event types strings \n",
    "df['EVENT_TYPE'] = df['EVENT_TYPE'].map(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask1 = (df['EVENT_TYPE']=='hurricane') | (df['EVENT_TYPE']=='wildfire') \n",
    "mask2 = (df['EVENT_TYPE']=='drought') | (df['EVENT_TYPE']=='tornado')\n",
    "df_mask1 = df.loc[mask1,:].copy()\n",
    "df_mask2 = df.loc[mask2,:].copy()\n",
    "df_weather = pd.DataFrame()\n",
    "df_weather = df_weather.append(df_mask1)\n",
    "df_weather = df_weather.append(df_mask2)\n",
    "df_weather.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(86608, 52)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_weather.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index                     0\n",
       "BEGIN_YEARMONTH           0\n",
       "BEGIN_DAY                 0\n",
       "BEGIN_TIME                0\n",
       "END_YEARMONTH             0\n",
       "END_DAY                   0\n",
       "END_TIME                  0\n",
       "EPISODE_ID                0\n",
       "EVENT_ID                  0\n",
       "STATE                     0\n",
       "STATE_FIPS                0\n",
       "YEAR                      0\n",
       "MONTH_NAME                0\n",
       "EVENT_TYPE                0\n",
       "CZ_TYPE                   0\n",
       "CZ_FIPS                   0\n",
       "CZ_NAME                   0\n",
       "WFO                       0\n",
       "BEGIN_DATE_TIME           0\n",
       "CZ_TIMEZONE               0\n",
       "END_DATE_TIME             0\n",
       "INJURIES_DIRECT           0\n",
       "INJURIES_INDIRECT         0\n",
       "DEATHS_DIRECT             0\n",
       "DEATHS_INDIRECT           0\n",
       "DAMAGE_PROPERTY       30459\n",
       "DAMAGE_CROPS          38852\n",
       "SOURCE                    0\n",
       "MAGNITUDE             86567\n",
       "MAGNITUDE_TYPE        86590\n",
       "FLOOD_CAUSE           86608\n",
       "CATEGORY              86271\n",
       "TOR_F_SCALE           58226\n",
       "TOR_LENGTH            58226\n",
       "TOR_WIDTH             58226\n",
       "TOR_OTHER_WFO         84218\n",
       "TOR_OTHER_CZ_STATE    84218\n",
       "TOR_OTHER_CZ_FIPS     84218\n",
       "TOR_OTHER_CZ_NAME     84218\n",
       "BEGIN_RANGE           59283\n",
       "BEGIN_AZIMUTH         59283\n",
       "BEGIN_LOCATION        56987\n",
       "END_RANGE             59233\n",
       "END_AZIMUTH           59233\n",
       "END_LOCATION          56987\n",
       "BEGIN_LAT             58232\n",
       "BEGIN_LON             58232\n",
       "END_LAT               58232\n",
       "END_LON               58232\n",
       "EPISODE_NARRATIVE      9195\n",
       "EVENT_NARRATIVE       35055\n",
       "DATA_SOURCE               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_weather.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dropping Data soucres \n",
    "We dropped data sources becuase we already know where the data set comes from and we do not need that column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weather.drop(columns='DATA_SOURCE', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dropping flood cause\n",
    "We dropped flood cause becuase it reports or estimates the cause of a flood which none of our current events cause a flood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weather.drop(columns='FLOOD_CAUSE', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Damage property \n",
    "The estimate amount of damage to property is reported like e.g. 10.00K = \\\\$10,000; 10.00M = \\\\$10,000,000. Also, we replace nulls with 0 for no damage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replacing nulls with 0\n",
    "df_weather['DAMAGE_PROPERTY'].fillna('0K', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting .01m to 100.00k\n",
    "df_weather['DAMAGE_PROPERTY'] = df_weather['DAMAGE_PROPERTY'].map(lambda x: '100K' if x == '.01M' else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting 0.00k to 0\n",
    "df_weather['DAMAGE_PROPERTY'] = df_weather['DAMAGE_PROPERTY'].map(lambda x: '0K' if (x == '0.00K') else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting 0.00k to 0\n",
    "df_weather['DAMAGE_PROPERTY'] = df_weather['DAMAGE_PROPERTY'].map(lambda x: '0K' if (x == '0') else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting 0.00k to 0\n",
    "df_weather['DAMAGE_PROPERTY'] = df_weather['DAMAGE_PROPERTY'].map(lambda x: '1K' if (x == 'K') else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting anything with .00K and adding ,000\n",
    "df_weather['DAMAGE_PROPERTY'] = df_weather['DAMAGE_PROPERTY'].map(lambda x: x[0:x.find('.00')]+'K' if x[-4::] == '.00K'  else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Coverting \n",
    "def converting_DP(string):\n",
    "    if string[-1::] == 'K':\n",
    "        return float(string[0:string.find('K')]) * 1_000\n",
    "    elif string[-1::] == 'M':\n",
    "        return float(string[0:string.find('M')]) * 1_000_000\n",
    "    else:\n",
    "        return float(string[0:string.find('B')]) * 1_000_000_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weather['DAMAGE_PROPERTY'] = df_weather['DAMAGE_PROPERTY'].map(converting_DP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Damage crops\n",
    "The estimate amount of damage to property is reported like e.g. 10.00K = \\\\$10,000; 10.00M = \\\\$10,000,000. Also, we replace nulls with 0 for no damage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replacing nulls with 0\n",
    "df_weather['DAMAGE_CROPS'].fillna('0K', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting 0.00k to 0\n",
    "df_weather['DAMAGE_CROPS'] = df_weather['DAMAGE_CROPS'].map(lambda x: '0K' if (x == '0') else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Coverting \n",
    "def converting_DC(string):\n",
    "    if string[-1::] == 'K':\n",
    "        return float(string[0:string.find('K')]) * 1_000\n",
    "    elif string[-1::] == 'M':\n",
    "        return float(string[0:string.find('M')]) * 1_000_000\n",
    "    else:\n",
    "        return float(string[0:string.find('B')]) * 1_000_000_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weather['DAMAGE_CROPS'] = df_weather['DAMAGE_CROPS'].map(converting_DC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Magnitude\n",
    "The measured extent of the magnitude type ~ only used for wind speeds (in knots) and hail size (in inches to the hundredth). All null values will be converted to 0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replacing nulls with 0\n",
    "df_weather['MAGNITUDE'].fillna(0.0, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MAGNITUDE_TYPE\n",
    " \n",
    ">EG = Wind Estimated Gust\n",
    "\n",
    ">ES = Estimated Sustained Wind\n",
    "\n",
    ">MS = Measured Sustained Wind\n",
    "\n",
    ">MG = Measured Wind Gust (no magnitude is included for instances of hail)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replacing nulls with 0\n",
    "df_weather['MAGNITUDE_TYPE'].fillna(\"No magnitude included\", inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Category\n",
    "Unknown (During the time of downloading this particular file, NCDC has never seen anything provided within this field.) **Note:** It could be Hurcaine strenghth.\n",
    "\n",
    "![huricane cats](../assets/hurricane_cats_image.jpg \"Categorries\")\n",
    "\n",
    "\n",
    "Image pulled from: [Here](https://open.lib.umn.edu/worldgeography/chapter/5-5-tropical-cyclones-hurricanes/) \n",
    "\n",
    "\n",
    "**Note:** A lot of data is missing from the data about the strenghth of a hurricane."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replacing nulls with 0\n",
    "df_weather['CATEGORY'].fillna(0.0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    86271\n",
       "1.0      275\n",
       "4.0       27\n",
       "2.0       19\n",
       "3.0       12\n",
       "5.0        4\n",
       "Name: CATEGORY, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_weather['CATEGORY'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TOR_F_SCALE\n",
    "\n",
    "Enhanced Fujita Scale describes the strength of the tornado based on the amount and type of damage caused by the tornado.  The F-scale of damage will vary in the destruction area; therefore, the highest value of the F-scale is recorded for each event. \n",
    "> EF0 –Light Damage (40 –72 mph) EFUs are also consider EF0. Do not believe me? Read it [here](https://en.wikipedia.org/wiki/Enhanced_Fujita_scale)\n",
    "\n",
    "> EF1 –Moderate Damage (73 –112 mph)\n",
    "\n",
    ">EF2 –Significant damage (113 –157 mph)\n",
    "\n",
    ">EF3 –Severe Damage (158 –206 mph)\n",
    "\n",
    ">EF4 –Devastating Damage (207 –260 mph)\n",
    "\n",
    ">EF5 –Incredible Damage (261 –318 mph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replacing nulls with no tornado\n",
    "df_weather['TOR_F_SCALE'].fillna('no tornado', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weather['TOR_F_SCALE'] = df_weather['TOR_F_SCALE'].map(lambda x: 'EF0' if x == 'F0' else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weather['TOR_F_SCALE'] = df_weather['TOR_F_SCALE'].map(lambda x: 'EF0' if x == 'EFU' else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weather['TOR_F_SCALE'] = df_weather['TOR_F_SCALE'].map(lambda x: 'EF1' if x == 'F1' else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weather['TOR_F_SCALE'] = df_weather['TOR_F_SCALE'].map(lambda x: 'EF2' if x == 'F2' else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weather['TOR_F_SCALE'] = df_weather['TOR_F_SCALE'].map(lambda x: 'EF3' if x == 'F3' else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weather['TOR_F_SCALE'] = df_weather['TOR_F_SCALE'].map(lambda x: 'EF4' if x == 'F4' else x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TOR_LENGTH\n",
    "\n",
    "Ex: 0.66, 1.05, 0.48\n",
    "\n",
    "Length of the tornado or tornado segment while on the ground (in miles to the tenth).\n",
    "\n",
    "Replacing with zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weather['TOR_LENGTH'].fillna(0.0, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TOR_WIDTH\n",
    "\n",
    "Ex:  25, 50, 2640, 10\n",
    "\n",
    "Width of the tornado or tornado segment while on the ground (in feet)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weather['TOR_WIDTH'].fillna(0.0, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TOR_OTHER_WFO\n",
    "\n",
    "Ex: DDC, ICT, TOP,OAX\n",
    "\n",
    "Indicates the continuation of a tornado segment as it crossed from one National Weather Service Forecast Office to another.  The subsequent WFO identifier is provided within this field.\n",
    "\n",
    "Will drop from the column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weather.drop(columns='TOR_OTHER_WFO', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TOR_OTHER_CZ_STATE\n",
    "\n",
    "Ex: KS, NE, OK\n",
    "\n",
    "The two-character representation for the state name of the continuing tornado segment as it crossed from one county or zone to another.  The subsequent 2-Letter State ID is provided within this field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weather['TOR_OTHER_CZ_STATE'].fillna('No Cross Over', inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TOR_OTHER_CZ_FIPS\n",
    "\n",
    "Ex: 41, 127, 153\n",
    "\n",
    "The FIPS number of the county entered by the continuing tornado segment as it crossed from one county to another.  The subsequent FIPS number is provided within this field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weather['TOR_OTHER_CZ_FIPS'].fillna(0, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TOR_OTHER_CZ_NAME\n",
    "\n",
    "Ex: DICKINSON, NEMAHA, SARPY\n",
    "\n",
    "The FIPS name of the county entered by the continuing tornado segment as it crossed from one county to another.  The subsequent county or zone name is provided within this field in ALL CAPS. No county crossed will eb replaced with the nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weather['TOR_OTHER_CZ_NAME'].fillna('No Cross Over', inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BEGIN_RANGE\n",
    "\n",
    "Ex: 0.59, 0.69, 4.84, 1.17 (in miles)\n",
    "\n",
    "The distance to the nearest tenth of a mile, to the location referenced below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weather['BEGIN_RANGE'].fillna(0, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BEGIN_AZIMUTH\n",
    "\n",
    "Ex:ENE, NW, WSW, S\n",
    "\n",
    "16-point compass direction from the location referenced below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weather['BEGIN_RANGE'].fillna('No direction', inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BEGIN_AZIMUTH\n",
    "\n",
    "Ex: PINELAND,  CENTER, ORRS, RUSK \n",
    "\n",
    "The name of city, town or village from which the range is calculated and the azimuth is determined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weather['BEGIN_AZIMUTH'].fillna('No direction', inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BEGIN_LOCATION\n",
    "\n",
    "begin_locationEx: PINELAND,  CENTER, ORRS, RUSK \n",
    "\n",
    "The name of city, town or village from which the range is calculated and the azimuth is determined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weather['BEGIN_LOCATION'].fillna('No location', inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### END_RANGE \n",
    "\n",
    "see begin_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weather['END_RANGE'].fillna(0, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### END_AZIMUTH\n",
    "\n",
    "see begin_azimuth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weather['END_AZIMUTH'].fillna('No direction', inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### END_LOCATION\n",
    "\n",
    "see begin_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weather['END_LOCATION'].fillna('No location', inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BEGIN_LAT\n",
    "\n",
    "Ex: 29.7898\n",
    "\n",
    "The latitude in decimal degrees of the begin point of the event or damage path \n",
    "\n",
    "Setting all nulls to null island."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weather['BEGIN_LAT'].fillna(0.0, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BEGIN_LON\n",
    "\n",
    "Ex: -98.6406\n",
    "\n",
    "The longitude in decimal degrees of the begin point of the event or damage path.\n",
    "\n",
    "setting to null island"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weather['BEGIN_LON'].fillna(0.0, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### END_LAT  \n",
    "\n",
    "Ex: 29.7158\n",
    "\n",
    "The latitude in decimal degrees of the end point of the event or damage path. Signed negative (-) if in the southern hemisphere>\n",
    "\n",
    "setting to null island"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weather['END_LAT'].fillna(0.0, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### END_LON\n",
    "\n",
    "Ex: -98.7744\n",
    "\n",
    "The longitude in decimal degrees of the end point of the event or damage path. Signed negative (-) if in the eastern hemisphere.\n",
    "\n",
    "setting to null island"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weather['END_LON'].fillna(0.0, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EPISODE_NARRATIVE  \n",
    "\n",
    "Ex: A strong upper level system over the southern Rockies lifted northeast across the plains causing an intense surface low pressure system and attendant warm front to lift into Nebraska.\n",
    "\n",
    "The episode narrative depicting the general nature and overall activity of the episode.  The National Weather Service creates the narrative. Nulls set as no entry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weather['EPISODE_NARRATIVE'].fillna('No entry', inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EVENT_NARRATIVE\n",
    "\n",
    "Ex:  Heavy rain caused flash flooding across parts of Wilber.  Rainfall of 2 to 3 inches fell across the area.\n",
    "\n",
    "The event narrative provides descriptive details of the individual event.  The National Weather Service creates the narrative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weather['EVENT_NARRATIVE'].fillna('No entry', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weather.to_csv('../data/clean_storm_data/clean_weather_data.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
